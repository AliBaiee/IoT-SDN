{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6-76.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AliBaiee/Rectangle/blob/master/6_76.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbHgsABV5rN7",
        "colab_type": "code",
        "outputId": "2c982d25-1ab4-4c7f-ca77-12718f20f4bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2NXW7o6HDsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = 'drive/My Drive/SOM/training.csv'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz80OWXlKBeU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import sqrt\n",
        "from numpy import (unravel_index, nditer, linalg, random, subtract,\n",
        "                   power, exp, pi, zeros, arange, outer, meshgrid, dot,\n",
        "                   logical_and, cov, argsort, linspace, transpose,\n",
        "                   einsum, prod, where, nan)\n",
        "from collections import defaultdict, Counter\n",
        "from warnings import warn\n",
        "from sys import stdout\n",
        "from time import time\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "def _build_iteration_indexes(data_len, num_iterations,\n",
        "                             verbose=False, random_order=False):\n",
        "    iterations = arange(num_iterations) % data_len\n",
        "    if random_order:\n",
        "        random.shuffle(iterations)\n",
        "    if verbose:\n",
        "        return _wrap_index__in_verbose(iterations)\n",
        "    else:\n",
        "        return iterations\n",
        "\n",
        "\n",
        "def _wrap_index__in_verbose(iterations):\n",
        "    \"\"\"Yields the values in iterations printing the status on the stdout.\"\"\"\n",
        "    m = len(iterations)\n",
        "    digits = len(str(m))\n",
        "    progress = '\\r [ {s:{d}} / {m} ] {s:3.0f}% - ? it/s'\n",
        "    progress = progress.format(m=m, d=digits, s=0)\n",
        "    stdout.write(progress)\n",
        "    beginning = time()\n",
        "    stdout.write(progress)\n",
        "    for i, it in enumerate(iterations):\n",
        "        yield it\n",
        "        sec_left = ((m - i + 1) * (time() - beginning)) / (i + 1)\n",
        "        time_left = str(timedelta(seconds=sec_left))[:7]\n",
        "        progress = '\\r [ {i:{d}} / {m} ]'.format(i=i + 1, d=digits, m=m)\n",
        "        progress += ' {p:3.0f}%'.format(p=100 * (i + 1) / m)\n",
        "        progress += ' - {time_left} left '.format(time_left=time_left)\n",
        "        stdout.write(progress)\n",
        "\n",
        "\n",
        "def fast_norm(x):\n",
        "    return sqrt(dot(x, x.T))\n",
        "\n",
        "\n",
        "def asymptotic_decay(learning_rate, t, max_iter):\n",
        "    return learning_rate / (1 + t / (max_iter / 2))\n",
        "\n",
        "\n",
        "class HappySom(object):\n",
        "    def __init__(self, x, y, input_len, sigma=1.0, learning_rate=0.5,\n",
        "                 decay_function=asymptotic_decay,\n",
        "                 neighborhood_function='gaussian', random_seed=None):\n",
        "        if sigma >= x or sigma >= y:\n",
        "            warn('Warning: sigma is too high for the dimension of the map.')\n",
        "\n",
        "        self._random_generator = random.RandomState(random_seed)\n",
        "\n",
        "        self._learning_rate = learning_rate\n",
        "        self._sigma = sigma\n",
        "        self._input_len = input_len\n",
        "        # random initialization\n",
        "        self._weights = self._random_generator.rand(x, y, input_len) * 2 - 1\n",
        "        self._weights /= linalg.norm(self._weights, axis=-1, keepdims=True)\n",
        "\n",
        "        self._activation_map = zeros((x, y))\n",
        "        self._neigx = arange(x)\n",
        "        self._neigy = arange(y)  # used to evaluate the neighborhood function\n",
        "        self._decay_function = decay_function\n",
        "\n",
        "        neig_functions = {'gaussian': self._gaussian,\n",
        "                          'mexican_hat': self._mexican_hat,\n",
        "                          'bubble': self._bubble,\n",
        "                          'triangle': self._triangle}\n",
        "\n",
        "        if neighborhood_function not in neig_functions:\n",
        "            msg = '%s not supported. Functions available: %s'\n",
        "            raise ValueError(msg % (neighborhood_function,\n",
        "                                    ', '.join(neig_functions.keys())))\n",
        "\n",
        "        if neighborhood_function in ['triangle',\n",
        "                                     'bubble'] and divmod(sigma, 1)[1] != 0:\n",
        "            warn('sigma should be an integer when triangle or bubble' +\n",
        "                 'are used as neighborhood function')\n",
        "\n",
        "        self.neighborhood = neig_functions[neighborhood_function]\n",
        "\n",
        "    def get_weights(self):\n",
        "        \"\"\"Returns the weights of the neural network.\"\"\"\n",
        "        return self._weights\n",
        "\n",
        "    def _activate(self, x):\n",
        "        s = subtract(x, self._weights)  # x - w\n",
        "        self._activation_map = linalg.norm(s, axis=-1)\n",
        "\n",
        "    def activate(self, x):\n",
        "        \"\"\"Returns the activation map to x.\"\"\"\n",
        "        self._activate(x)\n",
        "        return self._activation_map\n",
        "\n",
        "    def _gaussian(self, c, sigma):\n",
        "        \"\"\"Returns a Gaussian centered in c.\"\"\"\n",
        "        d = 2 * pi * sigma * sigma\n",
        "        ax = exp(-power(self._neigx - c[0], 2) / d)\n",
        "        ay = exp(-power(self._neigy - c[1], 2) / d)\n",
        "        return outer(ax, ay)  # the external product gives a matrix\n",
        "\n",
        "    def _mexican_hat(self, c, sigma):\n",
        "        \"\"\"Mexican hat centered in c.\"\"\"\n",
        "        xx, yy = meshgrid(self._neigx, self._neigy)\n",
        "        p = power(xx - c[0], 2) + power(yy - c[1], 2)\n",
        "        d = 2 * pi * sigma * sigma\n",
        "        return exp(-p / d) * (1 - 2 / d * p)\n",
        "\n",
        "    def _bubble(self, c, sigma):\n",
        "        ax = logical_and(self._neigx > c[0] - sigma,\n",
        "                         self._neigx < c[0] + sigma)\n",
        "        ay = logical_and(self._neigy > c[1] - sigma,\n",
        "                         self._neigy < c[1] + sigma)\n",
        "        return outer(ax, ay) * 1.\n",
        "\n",
        "    def _triangle(self, c, sigma):\n",
        "        \"\"\"Triangular function centered in c with spread sigma.\"\"\"\n",
        "        triangle_x = (-abs(c[0] - self._neigx)) + sigma\n",
        "        triangle_y = (-abs(c[1] - self._neigy)) + sigma\n",
        "        triangle_x[triangle_x < 0] = 0.\n",
        "        triangle_y[triangle_y < 0] = 0.\n",
        "        return outer(triangle_x, triangle_y)\n",
        "    \n",
        "    @staticmethod\n",
        "    def _check_iteration_number(num_iteration):\n",
        "        if num_iteration < 1:\n",
        "            raise ValueError('num_iteration must be > 1')\n",
        "\n",
        "    def _check_input_len(self, data):\n",
        "        \"\"\"Checks that the data in input is of the correct shape.\"\"\"\n",
        "        data_len = len(data[0])\n",
        "        if self._input_len != data_len:\n",
        "            msg = 'Received %d features, expected %d.' % (data_len,\n",
        "                                                          self._input_len)\n",
        "            raise ValueError(msg)\n",
        "\n",
        "    def winner(self, x):\n",
        "        \"\"\"Computes the coordinates of the winning neuron for the sample x.\"\"\"\n",
        "        self._activate(x)\n",
        "        return unravel_index(self._activation_map.argmin(),\n",
        "                             self._activation_map.shape)\n",
        "\n",
        "    def update(self, x, win, t, max_iteration):\n",
        "        eta = self._decay_function(self._learning_rate, t, max_iteration)\n",
        "        # sigma and learning rate decrease with the same rule\n",
        "        sig = self._decay_function(self._sigma, t, max_iteration)\n",
        "        # improves the performances\n",
        "        g = self.neighborhood(win, sig) * eta\n",
        "        # w_new = eta * neighborhood_function * (x-w)\n",
        "        self._weights += einsum('ij, ijk->ijk', g, x - self._weights)\n",
        "\n",
        "    def quantization(self, data):\n",
        "        self._check_input_len(data)\n",
        "        q = zeros(data.shape)\n",
        "        for i, x in enumerate(data):\n",
        "            q[i] = self._weights[self.winner(x)]\n",
        "        return q\n",
        "\n",
        "    def random_weights_init(self, data):\n",
        "        self._check_input_len(data)\n",
        "        it = nditer(self._activation_map, flags=['multi_index'])\n",
        "        while not it.finished:\n",
        "            rand_i = self._random_generator.randint(len(data))\n",
        "            self._weights[it.multi_index] = data[rand_i]\n",
        "            it.iternext()\n",
        "\n",
        "    def pca_weights_init(self, data):\n",
        "        if self._input_len == 1:\n",
        "            msg = 'The data needs at least 2 features for pca initialization'\n",
        "            raise ValueError(msg)\n",
        "        self._check_input_len(data)\n",
        "        if len(self._neigx) == 1 or len(self._neigy) == 1:\n",
        "            msg = 'PCA initialization inappropriate:' + \\\n",
        "                  'One of the dimensions of the map is 1.'\n",
        "            warn(msg)\n",
        "        pc_length, pc = linalg.eig(cov(transpose(data)))\n",
        "        pc_order = argsort(-pc_length)\n",
        "        for i, c1 in enumerate(linspace(-1, 1, len(self._neigx))):\n",
        "            for j, c2 in enumerate(linspace(-1, 1, len(self._neigy))):\n",
        "                self._weights[i, j] = c1 * pc[pc_order[0]] + c2 * pc[pc_order[1]]\n",
        "\n",
        "    def train(self, data, num_iteration, random_order=False, verbose=False):\n",
        "        self._check_iteration_number(num_iteration)\n",
        "        self._check_input_len(data)\n",
        "        iterations = _build_iteration_indexes(len(data), num_iteration,\n",
        "                                              verbose, random_order)\n",
        "        for t, iteration in enumerate(iterations):\n",
        "            self.update(data[iteration], self.winner(data[iteration]),\n",
        "                        t, num_iteration)\n",
        "        if verbose:\n",
        "            print('\\n quantization error:', self.quantization_error(data))\n",
        "            print(' topographic error:', self.topographic_error(data))\n",
        "\n",
        "    def train_random(self, data, num_iteration, verbose=False):\n",
        "        self.train(data, num_iteration, random_order=True, verbose=verbose)\n",
        "\n",
        "    def train_batch(self, data, num_iteration, verbose=False):\n",
        "        self.train(data, num_iteration, random_order=False, verbose=verbose)\n",
        "\n",
        "    def distance_map(self):\n",
        "        um = zeros((self._weights.shape[0], self._weights.shape[1]))\n",
        "        it = nditer(um, flags=['multi_index'])\n",
        "        while not it.finished:\n",
        "            for ii in range(it.multi_index[0] - 1, it.multi_index[0] + 2):\n",
        "                for jj in range(it.multi_index[1] - 1, it.multi_index[1] + 2):\n",
        "                    if (0 <= ii < self._weights.shape[0] and\n",
        "                            0 <= jj < self._weights.shape[1]):\n",
        "                        w_1 = self._weights[ii, jj, :]\n",
        "                        w_2 = self._weights[it.multi_index]\n",
        "                        um[it.multi_index] += fast_norm(w_1 - w_2)\n",
        "            it.iternext()\n",
        "        return um / um.max()\n",
        "\n",
        "    def activation_response(self, data):\n",
        "        self._check_input_len(data)\n",
        "        a = zeros((self._weights.shape[0], self._weights.shape[1]))\n",
        "        for x in data:\n",
        "            a[self.winner(x)] += 1\n",
        "        return a\n",
        "\n",
        "    def quantization_error(self, data):\n",
        "        self._check_input_len(data)\n",
        "        error = 0\n",
        "        for x in data:\n",
        "            error += fast_norm(x - self._weights[self.winner(x)])\n",
        "        return error / len(data)\n",
        "\n",
        "    def topographic_error(self, data):\n",
        "        self._check_input_len(data)\n",
        "        total_neurons = prod(self._activation_map.shape)\n",
        "        if total_neurons == 1:\n",
        "            warn('The topographic error is not defined for a 1-by-1 map.')\n",
        "            return nan\n",
        "\n",
        "        def are_adjacent(a, b):\n",
        "            \"\"\"Gives 0 if a and b are neighbors, 0 otherwise\"\"\"\n",
        "            return not (abs(a[0] - b[0]) <= 1 and abs(a[1] - b[1]) <= 1)\n",
        "\n",
        "        error = 0\n",
        "        for x in data:\n",
        "            self.activate(x)\n",
        "            activations = self._activation_map\n",
        "            flat_map = activations.reshape(total_neurons)\n",
        "            indexes = argsort(flat_map)\n",
        "            bmu_1 = unravel_index(where(indexes == 0)[0][0],\n",
        "                                  self._activation_map.shape)\n",
        "            bmu_2 = unravel_index(where(indexes == 1)[0][0],\n",
        "                                  self._activation_map.shape)\n",
        "            error += are_adjacent(bmu_1, bmu_2)\n",
        "        return error / float(len(data))\n",
        "    def win_map(self, data):\n",
        "        self._check_input_len(data)\n",
        "        winmap = defaultdict(list)\n",
        "        for x in data:\n",
        "            winmap[self.winner(x)].append(x)\n",
        "        return winmap\n",
        "\n",
        "    def labels_map(self, data, labels):\n",
        "        self._check_input_len(data)\n",
        "        if not len(data) == len(labels):\n",
        "            raise ValueError('data and labels must have the same length.')\n",
        "        winmap = defaultdict(list)\n",
        "        for x, l in zip(data, labels):\n",
        "            winmap[self.winner(x)].append(l)\n",
        "        for position in winmap:\n",
        "            winmap[position] = Counter(winmap[position])\n",
        "        return winmap\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONioI9fFQR7S",
        "colab_type": "code",
        "outputId": "9605567b-4f88-4fa6-8522-4f86530cda7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "# Unsupervised Learning\n",
        "import sys\n",
        "#sys.path.insert(0, '../')\n",
        "#import sklearn\n",
        "#from minisom import MiniSom\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.cross_validation import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import numpy as np\n",
        "from numpy.linalg import  norm\n",
        "#import matplotlib.pyplot as plt\n",
        "#from matplotlib.gridspec import GridSpec\n",
        "#%matplotlib inline\n",
        "\n",
        "#%load_ext autoreload\n",
        "\n",
        "data = np.genfromtxt(input_data, delimiter=',', usecols=(5, 6, 7, 25, 28, 37))\n",
        "data = np.apply_along_axis(lambda x: x/norm(x), 1, data)#https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.apply_along_axis.html \n",
        "labels = np.genfromtxt(input_data, delimiter=',', usecols=(43), dtype=str)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#from matplotlib.gridspec import GridSpec\n",
        "#%matplotlib inline\n",
        "\n",
        "#%load_ext autoreload\n",
        "\n",
        "data = np.genfromtxt(input_data, delimiter=',', usecols=(5, 6, 7, 25, 28, 37))\n",
        "data = np.apply_along_axis(lambda x: x/np.linalg.norm(x), 1, data)#https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.apply_along_axis.html \n",
        "labels = np.genfromtxt(input_data, delimiter=',', usecols=(43), dtype=str)\n",
        "\n",
        "# Initialization and training\n",
        "som = HappySom(20, 20, 6, sigma=3, learning_rate=0.5, neighborhood_function='triangle', random_seed=10)\n",
        "\n",
        "\n",
        "\n",
        "class_assignments = som.labels_map(data, labels)\n",
        "\n",
        "def classify(som, data, class_assignments):\n",
        "   \n",
        "    winmap = class_assignments\n",
        "    default_class = np.sum(list(winmap.values())).most_common()[0][0]#Return : Sum of the array elements (a scalar value if axis is none) or array with sum values along the specified axis.\n",
        "    # most_common function returns a list, which is sorted based on the count of the elements\n",
        "    result = []\n",
        "    for d in data:\n",
        "        win_position = som.winner(d)\n",
        "        if win_position in winmap:\n",
        "            result.append(winmap[win_position].most_common()[0][0])\n",
        "        else:\n",
        "            result.append(default_class)\n",
        "    return result\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels)\n",
        "\n",
        "som.pca_weights_init(X_train)#Principal Component Analysisn,initializing deep neural networks,https://arxiv.org/abs/1702.00177\n",
        "som.train_random(X_train, 5000, verbose=False)#verbose is an optional argument which can be used to report more information about an operation in your program.\n",
        "class_assignments = som.labels_map(X_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, classify(som, X_test, class_assignments)))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00       497\n",
            "      Backdoor       0.00      0.00      0.00       421\n",
            "           DoS       0.87      0.00      0.01      3106\n",
            "      Exploits       0.53      0.81      0.64      8353\n",
            "       Fuzzers       0.54      0.59      0.57      4562\n",
            "       Generic       1.00      0.98      0.99     10016\n",
            "        Normal       0.86      0.86      0.86     14051\n",
            "Reconnaissance       0.87      0.75      0.81      2554\n",
            "     Shellcode       0.31      0.09      0.14       248\n",
            "         Worms       0.00      0.00      0.00        28\n",
            "\n",
            "      accuracy                           0.76     43836\n",
            "     macro avg       0.50      0.41      0.40     43836\n",
            "  weighted avg       0.78      0.76      0.73     43836\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mywh0QcyURbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}